{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hcD2nPQvPOFM"
   },
   "source": [
    "# Generating Beyonce Lyrics using an RNN text generation model\n",
    "\n",
    "(adapted from the [tensorflow example](https://www.tensorflow.org/tutorials/sequences/text_generation), to run on [datahub.ucsd.edu](datahub.ucsd.edu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yG_n40gFzf9s"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening the txt file and examining the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pD_55cOxLkAb"
   },
   "outputs": [],
   "source": [
    "path_to_file = \"lyrics_text.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aavnuByVymwK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 272892 characters\n"
     ]
    }
   ],
   "source": [
    "#open the file and read it \n",
    "text = open(path_to_file, 'rb').read().decode(encoding = \"ISO-8859-1\")\n",
    "# length of text\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IlCgQBRVymwR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 unique characters\n"
     ]
    }
   ],
   "source": [
    "# Number of unique characters \n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNnrKn_lL-IJ"
   },
   "source": [
    "## Process the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFjSVAlWzf-N"
   },
   "source": [
    "## Vectorize the text\n",
    "\n",
    "Mapping strings to numerical representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IalZLbvOzf-F"
   },
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1VKcQHcymwb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'head down as ' ---- characters mapped to int ---- > [34 31 27 30  0 30 41 49 40  0 27 45  0]\n"
     ]
    }
   ],
   "source": [
    "# Example of the character mapping\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbmsf23Bymwe"
   },
   "source": [
    "## Prediction\n",
    "\n",
    "Creating the training examples and targets in order to use them for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0UHJDA39zf-O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "e\n",
      "a\n",
      "d\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l4hkDU3i7ozi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'head down as i watch my feet take turns hitting the ground eyes shut i find myself in love racing the'\n",
      "' earth and im soaked in your love and love was right in my path, in my grasp and me and you belong  i'\n",
      "' wanna run (run) smash into you i wanna run (run) and smash into you  ears closed what i hear no one '\n",
      "'else has to know cause i know that what we have is worth first place in gold and im soaked in your lo'\n",
      "'ve and love is right in my path, in my grasp and me and you belong, oh...  i wanna run (run) smash in'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNbw-iR0ymwj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'head down as i watch my feet take turns hitting the ground eyes shut i find myself in love racing th'\n",
      "Target data: 'ead down as i watch my feet take turns hitting the ground eyes shut i find myself in love racing the'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0eBu9WZG84i0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 34 ('h')\n",
      "  expected output: 31 ('e')\n",
      "Step    1\n",
      "  input: 31 ('e')\n",
      "  expected output: 27 ('a')\n",
      "Step    2\n",
      "  input: 27 ('a')\n",
      "  expected output: 30 ('d')\n",
      "Step    3\n",
      "  input: 30 ('d')\n",
      "  expected output: 0 (' ')\n",
      "Step    4\n",
      "  input: 0 (' ')\n",
      "  expected output: 30 ('d')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJdfPmdqzf-R"
   },
   "source": [
    "## Training batches\n",
    "\n",
    "Splitting the text into mangeable sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2pGotuNzf-S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = examples_per_epoch//BATCH_SIZE\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wjKZrC39ELy0"
   },
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    rnn = tf.keras.layers.CuDNNGRU\n",
    "    rnn2 = tf.keras.layers.CuDNNGRU\n",
    "else:\n",
    "    import functools\n",
    "    rnn = functools.partial(\n",
    "    tf.keras.layers.GRU, recurrent_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    rnn(rnn_units,\n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        stateful=True),\n",
    "\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwsrpOik5zhv"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab), \n",
    "  embedding_dim=embedding_dim, \n",
    "  rnn_units=rnn_units, \n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ubPo0_9Prjb"
   },
   "source": [
    "## Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C-_70kKAPrPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 78) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1): \n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vPGmAAXmVLGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           19968     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3935232   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 78)            79950     \n",
      "=================================================================\n",
      "Total params: 4,035,150\n",
      "Trainable params: 4,035,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uwv0gEkURfx1"
   },
   "source": [
    "### sampling from the output distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [],
   "source": [
    "# sampled_indices = tf.random.multinomial(example_batch_predictions[0], num_samples=1) # TF 1.12\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqFMUQc_UFgM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 26, 45, 28,  8,  3, 19, 59, 61,  2, 26, 48, 76, 65, 60, 52, 76,\n",
       "       69, 61, 36, 59, 31, 20, 61,  8, 73, 30, 34, 44, 54, 65,  2, 25, 57,\n",
       "       12, 24, 62,  0, 65, 56, 58, 19,  3, 49, 11,  1,  1, 11, 57, 70, 31,\n",
       "        4, 10,  3, 59, 41, 55, 10, 66, 60, 73, 10, 70, 75, 46,  2, 68, 48,\n",
       "       68, 19,  6,  4, 36, 28, 27, 37, 27, 36,  9, 56, 75, 12, 21, 73,  8,\n",
       "       66, 47, 57, 55, 50, 51, 44, 57, 50, 59, 13, 68,  5, 50, 51])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWcFwPwLSo05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " ' everything im asking for but you... stop making a big deal out of the little things, lets get carri'\n",
      "\n",
      "Next Char Predictions: \n",
      " '6`sb-&8\\x98\\x9c\"`vÂ£\\x99zÂ©\\x9cj\\x98e9\\x9c-³dhr}£\"]\\x931[\\x9d £\\x89\\x948&w0!!0\\x93\\xade(/&\\x98o\\x80/¦\\x99³/\\xad¿t\"¨v¨8+(jbakaj.\\x89¿1:³-¦u\\x93\\x80xyr\\x93x\\x982¨)xy'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UAjbjY03eiQ4"
   },
   "source": [
    "### Use an optimizer and a loss function to improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4HrXTACTdzY-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 78)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.357435\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DDl1_Een6rL0"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieSJdchZggUj"
   },
   "source": [
    "### Configure checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6fWTriUZP-n"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training'\n",
    "\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Ky3F_BhgkTW"
   },
   "source": [
    "### Execute the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yGBE2zxMMHs"
   },
   "outputs": [],
   "source": [
    "EPOCHS=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UK-hmKjYVoll",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "42/42 [==============================] - 235s 6s/step - loss: 3.5162\n",
      "Epoch 2/30\n",
      "42/42 [==============================] - 246s 6s/step - loss: 2.4968\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 214s 5s/step - loss: 2.2600\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 223s 5s/step - loss: 2.1148\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 214s 5s/step - loss: 1.9922\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 205s 5s/step - loss: 1.8803\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 202s 5s/step - loss: 1.7741\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 203s 5s/step - loss: 1.6775\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 205s 5s/step - loss: 1.5852\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 202s 5s/step - loss: 1.4979\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 200s 5s/step - loss: 1.4125\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 203s 5s/step - loss: 1.3355\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 207s 5s/step - loss: 1.2607\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 193s 5s/step - loss: 1.1882\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 189s 5s/step - loss: 1.1135\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 187s 4s/step - loss: 1.0437\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 187s 4s/step - loss: 0.9739\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 190s 5s/step - loss: 0.9036\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 197s 5s/step - loss: 0.8394\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 216s 5s/step - loss: 0.7721\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 221s 5s/step - loss: 0.7108\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 224s 5s/step - loss: 0.6496\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 226s 5s/step - loss: 0.5929\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 227s 5s/step - loss: 0.5419\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 232s 6s/step - loss: 0.4975\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 232s 6s/step - loss: 0.4580\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 235s 6s/step - loss: 0.4224\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 225s 5s/step - loss: 0.3912\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 204s 5s/step - loss: 0.3686\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 197s 5s/step - loss: 0.3474\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JIPcXllKjkdr"
   },
   "source": [
    "### Restore the latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zk2WJ2-XjkGz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training/ckpt_30'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LycQ-ot_jjyu"
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71xa6jnYVrAN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            19968     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3935232   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 78)             79950     \n",
      "=================================================================\n",
      "Total params: 4,035,150\n",
      "Trainable params: 4,035,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that generates the text with a prediction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    \n",
    "    #average number of characters in a Beyonce song \n",
    "    num_generate = 2139 \n",
    "\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    # we want to keep this temperature low because we want the text that is generated to\n",
    "    #as accurately represent Beyonce lyrics as it can\n",
    "    temperature = 1.0 \n",
    " \n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-e9e744808b1e>:22: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "love? why dont you neeved moliethe way   divation elves too much he wanna got the green light (whoa oh oh!) (uh uh huh uh uh uh huh uh uh) you got the green light (whoa oh oh oh oh oh oh oh oh oh!) oh ooh whoa whoa oh ooh whoa whoa oh ooh whoa whoa oh oh oh oh oh, oh oh oh oh oh ix awd thing i tolk my own keep tigns (i cant rung waiting doison my love in the urms a pecirs but i will complete and i thought it would be i will love you  i love to leave ito so scared of lonely and im scared of being the only sharmingood)  for you all in your equilld places got me looking so crazy right now your love got me looking so crazy youre through like a baby   free you thought wanna play it we the ones thats hey you reverse, and i impregnatea love and mine  (oh) cause we like a little too far...  with me better halo, halo, halo i can feel your halo, halo, halo i can see your heast  [verse 2:] you and me were standin on the sun feel everything standin on the sun) we remember sugar gote me dont be scared to be pray if you wanna aint a doctor but i can make you feel body i cant do running, know what i hear boy and noive got to hold on youve got a hold on, aste you leer my heart out i like the sweet it up lo que que le visis,de pieces away hime in it; girl, im a world-wide woman i been through this thing back this is for the time you knew you caushin the stage, ho i seine you cant fight its going down ill be rocking on my babe, rocking, rocking, on you, babe, rocking, rocking, jout ill never hit to hide the will be in love was never true if you let him take me from you i guess, i need you, i love you, i love i love to leave i love to see you walk into this with that  love, there are to aspelin, out me you wanted me let this happen and it proves, myself and i thats all i got in the bown for a green begrt waute i know that i let you know i got my at 26 youre the one that i never begin i drimp and my friends, real frieds and summing on that, suck and my man handle you watch me on your video phone on your video, video if you want me you can watch me on your video phone, jusn ast  aint oh, oh we gonna take it (for menight)  chec\n"
     ]
    }
   ],
   "source": [
    "#one of the most common words in a Beyonce song, a peer review suggested we used a word that was less random and not \n",
    "#a title of one of her songs \n",
    "print(generate_text(model, start_string=u\"love\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktovv0RFhrkn",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beyonce] we be all night, and everything a trut if you wanna know its your secret creole  baby) boys about not a dag, sen fighting through musions are again me, baby, nowill i wanna be for you like youre there for me you cunt me looking so crazy youre schoolin life?  theres nothing not to love about me how to fight temptation im not sereatent just we can prottless over second til we rendezvous  all i got comescare on your video, video if you wanta mouth like a birn this beats so damn quick when you say my day you know what sidgle lame and ime a do but just the temperature pon my dreams  baby boy not a day goes by without my find somebody else if i begced nobody heart wanna party wanna be, im good on any mlk boulevard (i go off), i gotta hold on youve got a hold on youve got the best of mustands  out to all the why im surrigas mama, all you taust  everything i see is you and i dont want no substitune bay i together its coorigged around what you love me from you yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah) get hard to the beat wite be hopeed oh loive my love, im really asking for is you... youre mine else 1:] i go (from now on im just a boy i know that this what we handed down bitches scow it for how it from here thats why youre beautiful   youre so sexy, baby, baby, baby, baby, baby, baby, bady? boy you stay on my mind but its your secret, and i need you, watch it, watch it, watch it, watch it, watch it, watch it, watch it, watch it, watch it, watched up and down blindly on the bayour eyes i feel like im about you i rather in the boss of a mat it cost to be  your honstan love in a star, feels dight, take whished up the partition fast driver, roll up the partition, please dont worth (we are nothin when me!  everything i do is just for you  everything i do is just for you  everything i do is just for you  everything i do is just for you  everything i do is juss for ins along about you their socue ituloup you a try porennas in a fool sing i love my mild i want you to touch you aint right now  i still care i still re\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"beyonce\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drunk in love)  you know it costs to be  your souce i love you  never can love all night long... (all night yeah)  sweet love all night long... (all night yeah)  good love all night long...  they sare asse you saving that we thank, thank) i cant believe we made it (this is what we made, made) this is what were thankful for (they never let me go) (uh uh huh shake up lookin corfidention i got a hot say forther way im not the peak, babe, the peak, babe, the peak, babe, the peak, babe, the peaks and beyour  off to catch myself but im out on your money, ive got a hold on, a hold on to me, brown like an eyes siftle all my ladies get it aint right we can chince to show we dont uve feel your halo, halo, halo i can see your halo, halo, halo i can feel your halo, halo, halo i can see your halo, halo, halo i can see your hurts, we shinike round whe hey  sit runcer oh, ladies, you put my love to the deal thats okay  well no, they id hadiama now fliest no seems to be the boss of me i just me so crazy i want it, woust up (doy-us while i tried and i got little kituy (uh huh uh uh) so i can feel your halo, halo, halo i can see your halo, halo, halo i bet everything you ow  [bridge 2 - track, like a nation elves out of my thouse vides my hands in my heart  im a will n beyonce y awissle, we always party  anda na:n, look iÃ¢ÂÂa let you go  so, i boty wolld, a good sopown  come on baby, dont fuck you hes por ut humble a bitter life without you i rock my girls you can say is yes, yes, yes you aint thinking bout you i aint thinking bout you i aint thinking bout you i aint thy by its a beautiful im in on anymarte at night, and everything about you fliend  i talk alone about it to the grande when i ambly some of a boss \" hap it feels boging i bet it sucks to be you right now word it and its bade or these people standin on the sun  feel everything stops. finally you pht my home  your hols you can let  go i got my top\"  live for you  counting on that, but she wants the world would revolve i thought the world would revolve i thought the world just come and lay uither at comes tough you kiss up and rub up and feel up under me tonight!  wont\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"drunk in love\")) #can use a phrase here \n",
    "#this is one of her song lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tractor, cause youre nocanor you back up, this is my dream then i am let as lo que es amar a una mujer sabrÃ£Â­a escuchar pues conozco el dolor ves me  my bedyone you at the time you know that shed befter my toming, keep me home oh oh, oh ah it could be far worse  closer lating wime ill be your neast goes around comes back my time is something that ive got the bresk my histrese dont work out that way, woust you dont need nobody else thats why youre the one that (i love all yÃ¢ÂÂall capricorn aquarius pisces aries taurus gemini cancer oh! leo virgo libra scorpio sagittarius i love all yÃ¢ÂÂall  i wike cause you his mind take you there world-wide woman www you know im the typh of you scream mus and a friend you reverse that cowgirl i trust you i keep my fingers off 25 huntre, as here i know its like i hove you  look at all than pincy the next do the thind i found a wock the ver thoughey no i see is oh, oh yeah  oh what do you do whatever i hear thit i moke away, cause youre no angel either, baby quems you see got a bog some coor  they world-wide woman would need so does, youre neakly hear for because i love the way you scream my namah   on baby, love me baby the w-y-y out [beyonce] oh baby, the alarian, all on my aspira. me they knd mean a trid complinted   if you got to, turn that cherry out, turn that cherry out i want you to turn that cherry out, turn that cherry out, turn that cherry out, turn that cherry out turn that ckrose [he skin the low me looking so crazy) you put my love on top, topat, top, flight boy, you but you a mat youre beautiful thats why youre bach boy, that they s all i need to fly i think i love that boy diam id new your aws ant now everything you talk to let go  by something in my own im comfifsly it and cam right you just and to be baby when im courting you can dona take it is ho bands!  im a visionarsive hon (beyonce, beyonce  miendr, now never ever tire for the pastion that plwow, where i be in my own home and ive tried and i together come on baby wont you hold on to me, hold on to me you and i together so good to you  [pre-hook]  [hook]\" [buy no nest the broken-hearted girl no, no\n"
     ]
    }
   ],
   "source": [
    "#using a word from a country song (not something you usually see in her songs) to see what the \n",
    "#model would produce\n",
    "print(generate_text(model, start_string=u\"tractor\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
